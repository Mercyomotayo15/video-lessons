{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dbda451-99f2-4b65-9669-2f032b9481d9",
   "metadata": {},
   "source": [
    "### Text Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cf180b-9614-450c-a4e7-790bf85206cc",
   "metadata": {},
   "source": [
    "##### Text Vectorization is the process of converting text into numerical representation. Converting Unstructured data to structured data(human readable language)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f844cd-798d-4516-8db1-545660b91896",
   "metadata": {},
   "source": [
    "### Methods to accomplish text vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c223e605-b253-4962-b200-534d1437d425",
   "metadata": {},
   "source": [
    " - ##### Brinary Term Frequency\n",
    "  - ##### Bag of Words\n",
    "  - ##### L1(Normalized Term Frequency)\n",
    "  - ##### L2(TFIDF)\n",
    "  - ##### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3b739f1-0319-47a4-acce-365a38a69510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset  - training data\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train=fetch_20newsgroups(subset=\"train\", shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e16b7a2-b66e-4f44-b22a-b8d3653bea34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fetch_20newsgroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2608d7ef-83ef-4fc1-8b79-759ca7ec3d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df5e7f81-30ca-4978-ab74-8e45a8d9474c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aff154e0-6bbf-4743-bf9c-ce5e2f87a9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 4, 4, ..., 3, 1, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e48e8eb3-bf5e-4e6f-b212-e668bca5e21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train.target) # number of target var (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "641e7ce0-85fb-4b12-9b30-4f6c825c44d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78308de3-33ce-4e15-a045-0768a8c28246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train.data) #number of input records/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b821363-5166-4e84-8108-e0d20a301f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#working with text documents: preprocessing and vectorizing :different types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5602df88-dacf-4c8e-bab3-8956373e9c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#types of data: 1.Structured: in numeric form.. csv file which has only numbers\n",
    "#Unstructured: not in numeric form.. ex: images, text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896b31e6-1e81-4205-88ff-5a74255644af",
   "metadata": {},
   "source": [
    "#### Count Vectorizer\n",
    "\n",
    "##### Count Vectorizer: Provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859bc6d4-e1a3-4678-a245-70472f8ca50a",
   "metadata": {},
   "source": [
    "##### Tockenization: basically refers to splitting up a larger body of text into smaller lines, words or even creating words for a non-English Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "003d7559-70e1-4823-b873-0b621ec77a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=[\"The quick brown fox jumped over the lazy dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6fb8383-d68c-49a4-98fd-2c189b6be760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The quick brown fox jumped over the lazy dog']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "159bf120-3827-4f61-8a17-ceb51c45e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#list of text documents\n",
    "#create the transform\n",
    "vectorizer=CountVectorizer()\n",
    "#tokenize and build vocab\n",
    "vector=vectorizer.fit_transform(text)\n",
    "#summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3728ef30-c57c-4249-a187-c4a6a994b457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8)\n",
      "[[1 1 1 1 1 1 1 2]]\n"
     ]
    }
   ],
   "source": [
    "print(vector.shape)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a846d925-e418-4016-9c12-f3c3cf9bfe85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 7,\n",
       " 'quick': 6,\n",
       " 'brown': 0,\n",
       " 'fox': 2,\n",
       " 'jumped': 3,\n",
       " 'over': 5,\n",
       " 'lazy': 4,\n",
       " 'dog': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b34c63bf-a4b9-4112-bc3f-a591ba4a3d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "#encode another document\n",
    "text2=[\"the brown puppy\"]\n",
    "vector=vectorizer.transform(text2)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47632111-ee60-4a1c-9b91-269eeefdc5c9",
   "metadata": {},
   "source": [
    "#### Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec0d150-6492-44f2-953d-aab3dd5eae4c",
   "metadata": {},
   "source": [
    "##### Bag of Words: A bag-of-word model, or BOW for short, is a way of extracting features from text for use in modelling, such as with machine learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278bff4f-b39f-4e27-80d7-57872fce7f3b",
   "metadata": {},
   "source": [
    "#### Word Frequencies with TFIDIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2935cfb-f52b-483e-a5e7-2df7ebf918c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11314x130107 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1787565 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#list of text documents\n",
    "text=twenty_train.data\n",
    "#create the transform\n",
    "vectorizer=TfidfVectorizer()\n",
    "#tokenize and build vocab\n",
    "vectorizer.fit_transform(text)\n",
    "#summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4834556-b6ad-4733-aaf3-90981b647d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector=vectorizer.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60554749-3033-494d-a256-fe869249c425",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 11.0 GiB for an array with shape (11314, 130107) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_204/1682547386.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1029\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 11.0 GiB for an array with shape (11314, 130107) and data type float64"
     ]
    }
   ],
   "source": [
    "X=vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6756158a-3d10-417e-89ff-7de6c9bc5057",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621f26cd-1b7b-48ea-91a5-ebd9b51ae638",
   "metadata": {},
   "outputs": [],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3e38e9df-1701-4f49-8e4f-a6163fb7f795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1ef3ad-ed7f-4bfa-a386-416eb8ea7815",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
